{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19b2f71-9bdb-483f-b495-4dd8c6af281d",
   "metadata": {},
   "source": [
    "# Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cfc711f-f105-4647-b3f2-835e15780db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "391028b1-a2ca-451c-bc5c-62ad83d0c17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the coordinates data set\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84910135-d284-499c-996c-2b1c2bf3f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and resize \n",
    "root= './train'\n",
    "names = []\n",
    "train_crude = []\n",
    "for file in os.listdir(root):\n",
    "    img = cv2.imread(os.path.join(root, file))#,cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "    train_crude.append(img)\n",
    "    names.append(file.split('.')[0])\n",
    "    \n",
    "data = np.stack( train_crude, axis=0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116f2e8-adaa-47b1-834f-fa61e1590893",
   "metadata": {},
   "source": [
    "### Extract feature CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a607331-1830-4af8-8255-6b50fef131ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf10d9e-a4cf-42de-abae-347f31572364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "base_model = ResNet50V2(weights='imagenet',input_shape=[163, 226,3],include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a8b0b73c-dbe5-48b8-9f62-0baecbe92c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features in batches and flatten\n",
    "feat = []\n",
    "for i in range(0,7500,500):\n",
    "    temp = base_model.predict(preprocess_input(data[i:i+500]))\n",
    "    feat.append(temp)\n",
    "    \n",
    "\n",
    "feat0 = np.concatenate(feat, axis=0) \n",
    "feat2 = [i.ravel() for i in feat0]\n",
    "feat2 = np.stack(feat2, axis=0) #these are the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a65ea7-507b-40f4-9e53-34264c5ea787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 98304)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfd944-40b9-46ba-988b-7a7184fc064b",
   "metadata": {},
   "source": [
    "### Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "360998f5-22a1-4869-97ad-56d6fc37d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "train = feat2[:7000]\n",
    "validation = feat2[7000:]\n",
    "\n",
    "neighTest = NearestNeighbors(n_neighbors=5)\n",
    "neighTest.fit(train)\n",
    "\n",
    "predictions = neighTest.kneighbors(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c4cc27e-a172-456f-90a8-9d9ae1e3c4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([437.69397, 452.00183, 455.92117, 459.7137 , 459.8171 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0] # Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3faf4168-0c41-4448-8a5c-701086c72889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2964,  684,  322, 3702, 6431], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1][0] # Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9daf3-52fd-44f7-a1d3-36f4b89dfd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,15))\n",
    "for ix,im in enumerate(predictions):\n",
    "    toShow = data[im]\n",
    "    plt.subplot(1,6,ix+1)\n",
    "    plt.imshow(toShow, cmap='gray')  \n",
    "    plt.title(im)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98522f8-5f60-48f6-8750-40cd2ce27a48",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65001b4c-a81a-4b08-a557-2cc7823bdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "#Generates de key points and descriptors of the neighbours of the images to be predicted\n",
    "\n",
    "key_points=[]\n",
    "descript=[]\n",
    "for  i, i_n in enumerate(predictions[1]): #Iterate over indices of predictions\n",
    "    # print(i_n)\n",
    "    kp_neighbours=[]\n",
    "    desc_neighbours=[]\n",
    "    for neigh in i_n: # Iterates over the indices of the k nearest neighbours of the instance being predicted\n",
    "        neighbour=data[neigh] # A neighbour of the instances being predicted\n",
    "        kp, des = sift.detectAndCompute(neighbour,None) # key points and descriptors of the neighbour of instance being predicted\n",
    "        kp_neighbours.append(kp)\n",
    "        desc_neighbours.append(des)\n",
    "        \n",
    "    key_points.append(kp_neighbours)\n",
    "    descript.append(desc_neighbours)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "b077bf00-abfb-4126-a344-625a6c53837f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descript[0]) #[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d843052-abf1-45ca-b9f2-985d79eaf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates de key points and descriptors of the images to be predicted\n",
    "\n",
    "validation_img=data[7000:]\n",
    "\n",
    "key_points_dev=[]\n",
    "descript_dev=[]\n",
    "\n",
    "for  img in validation_img: #Iterate over indices of predictions\n",
    "    # print(i_n)\n",
    "    kp, des = sift.detectAndCompute(img,None) # key points and descriptors of the instance being predicted\n",
    "    key_points_dev.append(kp)\n",
    "    descript_dev.append(des)\n",
    "    \n",
    "#descript_dev=np.array(descript_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f87955e-b62c-4252-914f-8b9831fa6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descript_dev[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "14a77884-50af-4dd6-9a62-3f64b69b3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(matcher,des1, des2):\n",
    "    # Matching descriptor using KNN algorithm\n",
    "    # print(des1,'\\n')\n",
    "    # print(des2)\n",
    "    try:\n",
    "        matches = matcher.knnMatch(des1,des2,k=2)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Store all good matches as per Lowe's Ratio test.\n",
    "    ratio = 0.6\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < ratio*n.distance:\n",
    "            good.append(m)\n",
    "    return len(good)\n",
    "\n",
    "def match(desc_list1, desc_list2):\n",
    "    \n",
    "    # FLANN parameters and initialize\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    best_neighbours_matched=[]\n",
    "    for i, desc1 in enumerate(desc_list1):\n",
    "        # print('\\n\\n')\n",
    "        # print('image {}'.format(i))\n",
    "        matches_list=[]\n",
    "        ind_neighbour=[]\n",
    "        for j, desc2 in enumerate(desc_list2[i]):\n",
    "            #print(j)\n",
    "            if desc2 is not None:\n",
    "                #print('neighb {}'.format(j))\n",
    "                n_matches = find_matches(flann, desc1, desc2)\n",
    "                if n_matches is not None:\n",
    "                    ind_neighbour.append(predictions[1][i][j]) #Appends index in the data of the neighbour from the image being predicted\n",
    "                    matches_list.append(n_matches) #Appends matches between the current neighbour and the instance being predicted\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        #print('len ind neigh',ind_neighbour)\n",
    "        #print('len matches list',matches_list)\n",
    "        neighb_matches=np.stack([ind_neighbour,matches_list],axis=1) #Creates numpy array. Rows are descriptors of different neighbours. \n",
    "                                                                     # First column is index in the data, Second column is how many matches that neighbour has with the current instance\n",
    "        neighb_matches=neighb_matches[neighb_matches[:, 1].argsort()[::-1][:len(matches_list)]]  #Sorts array in descending order, more matches on top and less matches at the bottom :5 is the number of neighbours\n",
    "        #print(neighb_matches)\n",
    "        best_neighbours_matched.append(neighb_matches)\n",
    "    \n",
    "    return best_neighbours_matched\n",
    "                                 \n",
    "k_best_matches=match(descript_dev,descript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b998b8ec-6dd7-4032-92c0-ffb04e1a64bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4436,    6],\n",
       "       [ 217,    2]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_best_matches"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
