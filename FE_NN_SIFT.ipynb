{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19b2f71-9bdb-483f-b495-4dd8c6af281d",
   "metadata": {},
   "source": [
    "# Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfc711f-f105-4647-b3f2-835e15780db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84910135-d284-499c-996c-2b1c2bf3f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and resize \n",
    "root= './train'\n",
    "\n",
    "def load_data(root_path):\n",
    "    names = []\n",
    "    train_crude = []\n",
    "\n",
    "    for file in os.listdir(root):\n",
    "        img = cv2.imread(os.path.join(root, file))#,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "        train_crude.append(img)\n",
    "        names.append(file.split('.')[0])\n",
    "    \n",
    "    data = np.stack( train_crude, axis=0 )\n",
    "    return names, data\n",
    "\n",
    "names, data = load_data(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a919eda5-223d-4da5-b6f5-5b62d2095247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7500, 163, 226, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116f2e8-adaa-47b1-834f-fa61e1590893",
   "metadata": {},
   "source": [
    "## Extract feature CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcf10d9e-a4cf-42de-abae-347f31572364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "base_model = ResNet50V2(weights='imagenet',input_shape=[163, 226,3],include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8b0b73c-dbe5-48b8-9f62-0baecbe92c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features in batches and flatten\n",
    "\n",
    "def generate_features(data,base_model, test = False):\n",
    "    feat = []\n",
    "    batch_size = 500\n",
    "    num_samples = data.shape[0]\n",
    "    if test:\n",
    "        batch_size = 10\n",
    "    for i in range(0,num_samples,batch_size):\n",
    "        temp = base_model.predict(preprocess_input(data[i:i + batch_size]))\n",
    "        feat.append(temp)\n",
    "\n",
    "\n",
    "    feat0 = np.concatenate(feat, axis = 0) \n",
    "    feat2 = [i.ravel() for i in feat0]\n",
    "    feat2 = np.stack(feat2, axis = 0) #these are the features\n",
    "    \n",
    "    return feat2\n",
    "\n",
    "feat = generate_features(data,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0a65ea7-507b-40f4-9e53-34264c5ea787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 98304)\n"
     ]
    }
   ],
   "source": [
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfd944-40b9-46ba-988b-7a7184fc064b",
   "metadata": {},
   "source": [
    "## Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360998f5-22a1-4869-97ad-56d6fc37d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_nearest_neighbours(features, *args):\n",
    "    \n",
    "    neighTest = NearestNeighbors(n_neighbors = 5)\n",
    "    predictions = None\n",
    "    \n",
    "    if not args:\n",
    "        train = features[:7000]\n",
    "        validation = features[7000:]\n",
    "        neighTest.fit(train)\n",
    "        predictions = neighTest.kneighbors(validation)\n",
    "    else:\n",
    "        test_features = args[0] \n",
    "        neighTest.fit(features)\n",
    "        predictions = neighTest.kneighbors(test_features)\n",
    "    \n",
    "    return predictions\n",
    "        \n",
    "predictions = get_nearest_neighbours(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4cc27e-a172-456f-90a8-9d9ae1e3c4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([437.64816, 450.4767 , 455.55823, 458.5046 , 458.75742],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0] # Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3faf4168-0c41-4448-8a5c-701086c72889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2964,  684,  322, 6431, 2433], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1][0] # Indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98522f8-5f60-48f6-8750-40cd2ce27a48",
   "metadata": {},
   "source": [
    "## SIFT extraction for neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65001b4c-a81a-4b08-a557-2cc7823bdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates de key points and descriptors of the neighbours of the images to be predicted\n",
    "\n",
    "def generate_descriptors_neighbours(predictions):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    key_points = []\n",
    "    descriptors = []\n",
    "    for  i, i_n in enumerate(predictions[1]): #Iterate over indices of the predicted nearest neighbours\n",
    "        # print(i_n)\n",
    "        kp_neighbours = []\n",
    "        desc_neighbours = []\n",
    "        for neigh in i_n: # Iterates over the indices of the k nearest neighbours of the instance being predicted\n",
    "            img = data[neigh]\n",
    "            gray_neighbour = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# A neighbour of the instances being predicted\n",
    "            kp, des = sift.detectAndCompute(gray_neighbour,None) # key points and descriptors of the neighbour of instance being predicted\n",
    "            kp_neighbours.append(kp)\n",
    "            desc_neighbours.append(des)\n",
    "\n",
    "        key_points.append(kp_neighbours)\n",
    "        descriptors.append(desc_neighbours)\n",
    "    \n",
    "    return key_points, descriptors\n",
    "\n",
    "kpts_target_cand,descriptors_cand = generate_descriptors_neighbours(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a114d2e6-fa10-47ce-80a4-0f3facd2c94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[  5.,   1.,  15., ...,   2.,  27.,  20.],\n",
       "        [  1.,  10.,  14., ...,   1.,   0.,   0.],\n",
       "        [  4.,   9.,   7., ...,  12.,   0.,   0.],\n",
       "        ...,\n",
       "        [ 14.,   2.,   1., ...,   3.,   9.,   3.],\n",
       "        [  1.,  49.,  35., ...,   0.,   0.,   0.],\n",
       "        [ 86., 108.,   1., ...,   0.,   0.,   0.]], dtype=float32),\n",
       " array([[ 0.,  1., 62., ...,  2.,  0.,  2.],\n",
       "        [ 0.,  0., 61., ..., 12.,  2.,  9.],\n",
       "        [39.,  1.,  0., ...,  1.,  3.,  1.],\n",
       "        ...,\n",
       "        [ 8.,  0.,  0., ..., 42., 15.,  1.],\n",
       "        [ 2.,  0.,  0., ...,  5.,  2.,  4.],\n",
       "        [ 0.,  5., 76., ...,  0.,  0.,  0.]], dtype=float32),\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors_cand[0])\n",
    "descriptors_cand[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d843052-abf1-45ca-b9f2-985d79eaf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates de key points and descriptors of the images to be predicted\n",
    "validation_img = data[7000:]\n",
    "\n",
    "def generate_descriptors(data_img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    key_points = []\n",
    "    descript = []\n",
    "\n",
    "    for  img in data_img: #Iterate over indices of predictions\n",
    "        # print(i_n)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = sift.detectAndCompute(gray,None) # key points and descriptors of the instance being predicted\n",
    "        key_points.append(kp)\n",
    "        descript.append(des)\n",
    "    \n",
    "    return key_points, descript\n",
    "\n",
    "kpts_target,descriptors_target = generate_descriptors(validation_img)\n",
    "#descript_dev=np.array(descript_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f87955e-b62c-4252-914f-8b9831fa6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors_target)\n",
    "len(descriptors_target[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da728075-8e66-4b2e-86b8-b8894f5d5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PtsWrapper():\n",
    "    def __init__(self, data):\n",
    "        self.puntos = data\n",
    "    \n",
    "    def get_points():\n",
    "        return self.puntos\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14a77884-50af-4dd6-9a62-3f64b69b3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(matcher,kp1, des1, kp2, des2):\n",
    "    # Matching descriptor using KNN algorithm\n",
    "    try:\n",
    "        matches = matcher.knnMatch(des1, des2, k = 2)\n",
    "    except:\n",
    "        #print('exception in find matches')\n",
    "        return None, None, None\n",
    "\n",
    "    # Store all good matches as per Lowe's Ratio test.\n",
    "    ratio = 0.6\n",
    "    num_matches = 0\n",
    "    ptsL = []\n",
    "    ptsR = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < ratio * n.distance:\n",
    "            num_matches += 1\n",
    "            ptsL.append(kp1[m.queryIdx].pt)\n",
    "            ptsR.append(kp2[m.trainIdx].pt)\n",
    "            \n",
    "    ptsL = np.int32(ptsL)\n",
    "    ptsR = np.int32(ptsR)\n",
    "    \n",
    "    return num_matches, ptsL, ptsR\n",
    "\n",
    "def match(kpts_target ,desc_targets, kpts_candidates, desc_candidates, predictions):\n",
    "    \"\"\"Finds the neighbours that best match the target image based on their descriptors\n",
    "\n",
    "    Keyword arguments:\n",
    "    kpts_target -- list of key points from the target images \n",
    "    desc_targets -- list of descriptors from the target images \n",
    "    kpts_candidates -- list (of lists) of key points from the nearest neighbours of the target images\n",
    "    desc_candidates -- list (of lists) of descriptors from the nearest neighbours of the target images\n",
    "    predictions = tuple containing two matrices. The first one with the distance from the nearest neighbours to the target images. \n",
    "                                                The second one with the indices of the nearest neighbours from the target images.\n",
    "    Returns a matrix of matrices. Dim 0 corresponds to a matrix containing information relative to the neighbours of the target image.\n",
    "                                The matrix is of shape (number of neighbours matched ,3) where the first column is the index of the neighbour in the coordinates file,\n",
    "                                Second column indicates the number of matches of that neighbour with the target image\n",
    "                                Third column is an object of class ptsWrapper that contains the list of matched  key points of that neighbour with the target image (use get_points() to access them) \n",
    "    \"\"\"\n",
    "    \n",
    "    # FLANN parameters and initialize\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks = 50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    best_neighbours_matched = []\n",
    "    for i, target in enumerate(desc_targets):\n",
    "        # print('\\n\\n')\n",
    "        # print('image {}'.format(i))\n",
    "        matches_list = []\n",
    "        ind_neighbour = []\n",
    "        left_pts_list = []\n",
    "        right_pts_list = []\n",
    "        for j, candidate in enumerate(desc_candidates[i]):\n",
    "            #print(j)\n",
    "            if candidate is not None:\n",
    "                #print('neighb {}'.format(j))\n",
    "                n_matches, pts_L, pts_R = find_matches(flann, kpts_target[i], target,  kpts_candidates[i][j], candidate)\n",
    "                if n_matches is not None:\n",
    "                    ind_neighbour.append(predictions[1][i][j]) #Appends index in the data of the neighbour from the image being predicted\n",
    "                    matches_list.append(n_matches) #Appends matches between the current neighbour and the instance being predicted\n",
    "                    left_pts_list.append(PtsWrapper(pts_L))\n",
    "                    right_pts_list.append(PtsWrapper(pts_R))\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        #print('len ind neigh',ind_neighbour)\n",
    "        #print('len matches list',matches_list)\n",
    "        neighb_matches = np.stack([ind_neighbour, matches_list, left_pts_list, right_pts_list], axis = 1) #Creates numpy array. Rows are descriptors of different neighbours. \n",
    "                                                                     # First column is index in the data, Second column is how many matches that neighbour has with the current instance\n",
    "        neighb_matches = neighb_matches[neighb_matches[:, 1].argsort()[::-1][:len(matches_list)]]  #Sorts array in descending order, more matches on top and less matches at the bottom :5 is the number of neighbours\n",
    "        #print(neighb_matches)\n",
    "        best_neighbours_matched.append(neighb_matches)\n",
    "    \n",
    "    return best_neighbours_matched\n",
    "                                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d446b1-9551-4f10-b0fc-c3338d62a5d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "755fd7b8-e103-4213-af74-62cff650abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best_matches = match(kpts_target, descriptors_target, kpts_target_cand, descriptors_cand, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4098d012-9532-482a-9f4a-1cd95601f2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98, 78],\n",
       "       [98, 78]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## See output example below to understand the output of the function match()\n",
    "exmp = k_best_matches[0][0][2]\n",
    "exmp.puntos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "32cf9f1e-e04e-4635-935c-974b0fef8637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.PtsWrapper at 0x1dba44507c8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exmp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76bfe75-9af0-4aad-acac-c631d9a7c2a1",
   "metadata": {},
   "source": [
    "## Get Essential matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9d8b508-0071-481b-8c40-a1ae920c40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def camera_matrix(horizontal, vertical, img):\n",
    "    x = img.shape[0] / 2\n",
    "    y = img.shape[1] / 2\n",
    "    f_x = (x / np.tan(horizontal * (np.pi/180)/2)) \n",
    "    f_y = (y / np.tan(vertical * (np.pi/180)/2))\n",
    "    return np.array([[f_x,0,x],\n",
    "                     [0,f_y,y],\n",
    "                     [0, 0, 1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "825a68b9-c0c5-4931-a5b2-7e3abfbb910c",
   "metadata": {},
   "outputs": [],
   "source": [
    "F, mask = cv2.findFundamentalMat(k_best_matches[0][0][2].puntos,k_best_matches[0][0][3].puntos,cv2.FM_LMEDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4069af0-03a2-4e41-9c4d-c18a4c3eabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = camera_matrix(73.7, 53.1, data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87811108-3d92-41c5-8844-8fc0bd7ae24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = K.t*F*K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdb23c55-7fcd-477d-9f87-5ca4456de5ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[108.7453233 ,   0.        ,   0.        ],\n",
       "       [  0.        , 226.14849934,   0.        ],\n",
       "       [ 81.5       , 113.        ,   1.        ]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665528d-9004-4939-a898-cf5fc6e06597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a599e47d-c5fc-4b63-9c74-857af361478c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[583.28297864,   0.        , 320.        ],\n",
       "       [  0.        , 579.41125497, 240.        ],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "camera_matrix(57.5, 45, np.zeros((640,480)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1e945-4b43-4de2-b58d-9bae48f4266d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## TEST predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a475d1f4-f410-44b5-a289-88f3d83447e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root= './test'\n",
    "names_test, test_img = load_data(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "62492e99-38a2-4c5f-a104-b71e0ca1fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat=generate_features(test_img,base_model, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5a03ca6-4dd2-4791-bbce-f54f71f53224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 98304)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "206a54b1-c125-426f-acc5-0c77a56a4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_neigh = get_nearest_neighbours(feat, test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d80997f-2708-4f76-93c8-2f57d0b19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_neigh, descript_neigh = generate_descriptors_neighbours(predicted_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e8eda8b-8e03-4999-9ed4-ef44def0f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps_target, descript_target=generate_descriptors(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f725788-d7d8-4b48-9bcb-89107036342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best_matches_test=match(kps_target, descript_target, kps_neigh, descript_neigh,predicted_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b987af95-f547-4aba-8322-bed243796dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def give_preds(k_best_matches_test,predicted_neigh, df_coordinates,names_test):\n",
    "    \"\"\"Peforms the prediction for the test_set using the k best matches or the best neighbours in case there are no matches produced by SIFT\n",
    "\n",
    "    Keyword arguments:\n",
    "    k_best_matches_test -- k best matches list generated by feature matching using SIFT\n",
    "    predicted_neigh -- predicted k nearest neighbours by the pre-trained model\n",
    "    df_coordinates -- dataframe where the coordinates of the training points are\n",
    "    names_test =\n",
    "    \"\"\"\n",
    "    pred_coordinates=[]\n",
    "    record_no_matches=[]\n",
    "    for i, best in enumerate(k_best_matches_test):\n",
    "        if best.size != 0:\n",
    "            index_best=best[0][0] # This is the index of the neighbour with more matches\n",
    "            pred_coordinates.append([names_test[i],df_coordinates.loc[index_best,'x'],df_coordinates.loc[index_best,'y']])\n",
    "        else:\n",
    "            # if there were no matches, use the average of the locations of the neighbours found by the pre-trained model\n",
    "            num_neighbors=2\n",
    "            x_coord_arr=np.array([df_coordinates.loc[j,'x'] for j in predicted_neigh[1][i]])\n",
    "            x_coord=x_coord_arr[:num_neighbors].mean()\n",
    "            y_coord_arr=np.array([df_coordinates.loc[j,'y'] for j in predicted_neigh[1][i]])\n",
    "            y_coord=y_coord_arr[:num_neighbors].mean()\n",
    "            pred_coordinates.append([names_test[i], x_coord, y_coord])\n",
    "    \n",
    "    array_preds=np.stack(pred_coordinates, axis=0)\n",
    "   \n",
    "    df_predictions=pd.DataFrame(array_preds, columns=['id','x','y'])\n",
    "    return df_predictions\n",
    "\n",
    "#Load the coordinates data set\n",
    "coordinates = pd.read_csv('train.csv')\n",
    "            \n",
    "df_preds = give_preds(k_best_matches_test, predicted_neigh, coordinates,names_test)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6934096a-cf47-4925-ae85-a4906740a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv('resnet_knn_sift2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fb24e09c-cc3d-4e89-8620-5d5c38e767a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[323.00092, 396.38666, 405.2545 , 406.16324, 406.93503],\n",
       "        [402.14273, 403.9036 , 405.39566, 410.11633, 415.00497],\n",
       "        [404.2133 , 407.3134 , 407.66003, 410.6764 , 412.31476],\n",
       "        ...,\n",
       "        [523.98206, 528.6266 , 529.6274 , 531.1956 , 531.5879 ],\n",
       "        [431.3342 , 439.16223, 439.67752, 441.6945 , 441.93524],\n",
       "        [375.47748, 380.55112, 382.6583 , 385.34314, 385.38266]],\n",
       "       dtype=float32),\n",
       " array([[3158, 7050, 5008, 6206,  290],\n",
       "        [3338, 1605, 6744, 7364, 2334],\n",
       "        [2334, 4004, 6860, 3020, 1961],\n",
       "        ...,\n",
       "        [2334, 3020, 5285, 6414, 1961],\n",
       "        [2334, 2433, 4543, 4008, 6949],\n",
       "        [2334, 2433,  322, 2849, 3809]], dtype=int64))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_neigh\n",
    "\n",
    "def transform predicted(predictions):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
