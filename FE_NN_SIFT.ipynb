{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19b2f71-9bdb-483f-b495-4dd8c6af281d",
   "metadata": {},
   "source": [
    "# Mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cfc711f-f105-4647-b3f2-835e15780db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy import ndimage \n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "391028b1-a2ca-451c-bc5c-62ad83d0c17f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG2744_1</td>\n",
       "      <td>-9.380678</td>\n",
       "      <td>3.58272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG2744_2</td>\n",
       "      <td>-9.380678</td>\n",
       "      <td>3.58272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG2744_3</td>\n",
       "      <td>-9.380678</td>\n",
       "      <td>3.58272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG2744_4</td>\n",
       "      <td>-9.380678</td>\n",
       "      <td>3.58272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG2744_5</td>\n",
       "      <td>-9.380678</td>\n",
       "      <td>3.58272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>IMG4243_1</td>\n",
       "      <td>-4.680678</td>\n",
       "      <td>35.18272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>IMG4243_2</td>\n",
       "      <td>-4.680678</td>\n",
       "      <td>35.18272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>IMG4243_3</td>\n",
       "      <td>-4.680678</td>\n",
       "      <td>35.18272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>IMG4243_4</td>\n",
       "      <td>-4.680678</td>\n",
       "      <td>35.18272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>IMG4243_5</td>\n",
       "      <td>-4.680678</td>\n",
       "      <td>35.18272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id         x         y\n",
       "0     IMG2744_1 -9.380678   3.58272\n",
       "1     IMG2744_2 -9.380678   3.58272\n",
       "2     IMG2744_3 -9.380678   3.58272\n",
       "3     IMG2744_4 -9.380678   3.58272\n",
       "4     IMG2744_5 -9.380678   3.58272\n",
       "...         ...       ...       ...\n",
       "7495  IMG4243_1 -4.680678  35.18272\n",
       "7496  IMG4243_2 -4.680678  35.18272\n",
       "7497  IMG4243_3 -4.680678  35.18272\n",
       "7498  IMG4243_4 -4.680678  35.18272\n",
       "7499  IMG4243_5 -4.680678  35.18272\n",
       "\n",
       "[7500 rows x 3 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84910135-d284-499c-996c-2b1c2bf3f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images and resize \n",
    "root= './train'\n",
    "\n",
    "def load_data(root_path):\n",
    "    names = []\n",
    "    train_crude = []\n",
    "\n",
    "    for file in os.listdir(root):\n",
    "        img = cv2.imread(os.path.join(root, file))#,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (img.shape[1]//3,img.shape[0]//3))\n",
    "        train_crude.append(img)\n",
    "        names.append(file.split('.')[0])\n",
    "    \n",
    "    data = np.stack( train_crude, axis=0 )\n",
    "    return names, data\n",
    "\n",
    "names, data=load_data(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a919eda5-223d-4da5-b6f5-5b62d2095247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7500"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3116f2e8-adaa-47b1-834f-fa61e1590893",
   "metadata": {},
   "source": [
    "### Extract feature CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a607331-1830-4af8-8255-6b50fef131ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcf10d9e-a4cf-42de-abae-347f31572364",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "\n",
    "base_model = ResNet50V2(weights='imagenet',input_shape=[163, 226,3],include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8b0b73c-dbe5-48b8-9f62-0baecbe92c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get features in batches and flatten\n",
    "\n",
    "def generate_features(data,base_model, test=False):\n",
    "    feat = []\n",
    "    batch_size=500\n",
    "    num_samples=data.shape[0]\n",
    "    if test:\n",
    "        batch_size=10\n",
    "    for i in range(0,num_samples,batch_size):\n",
    "        temp = base_model.predict(preprocess_input(data[i:i+batch_size]))\n",
    "        feat.append(temp)\n",
    "\n",
    "\n",
    "    feat0 = np.concatenate(feat, axis=0) \n",
    "    feat2 = [i.ravel() for i in feat0]\n",
    "    feat2 = np.stack(feat2, axis=0) #these are the features\n",
    "    \n",
    "    return feat2\n",
    "\n",
    "feat=generate_features(data,base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0a65ea7-507b-40f4-9e53-34264c5ea787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7500, 98304)\n"
     ]
    }
   ],
   "source": [
    "print(feat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbfd944-40b9-46ba-988b-7a7184fc064b",
   "metadata": {},
   "source": [
    "### Nearest neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360998f5-22a1-4869-97ad-56d6fc37d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def get_nearest_neighbours(features, *args):\n",
    "    \n",
    "    neighTest = NearestNeighbors(n_neighbors=5)\n",
    "    predictions=None\n",
    "    \n",
    "    if not args:\n",
    "        train = features[:7000]\n",
    "        validation = features[7000:]\n",
    "        neighTest.fit(train)\n",
    "        predictions = neighTest.kneighbors(validation)\n",
    "    else:\n",
    "        test_features=args[0] \n",
    "        neighTest.fit(features)\n",
    "        predictions=neighTest.kneighbors(test_features)\n",
    "    \n",
    "    return predictions\n",
    "        \n",
    "predictions=get_nearest_neighbours(feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c4cc27e-a172-456f-90a8-9d9ae1e3c4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([437.69397, 452.00183, 455.92117, 459.7137 , 459.8171 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][0] # Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3faf4168-0c41-4448-8a5c-701086c72889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2964,  684,  322, 3702, 6431], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1][0] # Indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be9daf3-52fd-44f7-a1d3-36f4b89dfd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(15,15))\n",
    "for ix,im in enumerate(predictions):\n",
    "    toShow = data[im]\n",
    "    plt.subplot(1,6,ix+1)\n",
    "    plt.imshow(toShow, cmap='gray')  \n",
    "    plt.title(im)\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98522f8-5f60-48f6-8750-40cd2ce27a48",
   "metadata": {},
   "source": [
    "### SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "65001b4c-a81a-4b08-a557-2cc7823bdef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates de key points and descriptors of the neighbours of the images to be predicted\n",
    "\n",
    "def generate_descriptors_neighbours(predictions):\n",
    "    sift = cv2.SIFT_create()\n",
    "\n",
    "    key_points=[]\n",
    "    descriptors=[]\n",
    "    for  i, i_n in enumerate(predictions[1]): #Iterate over indices of the predicted nearest neighbours\n",
    "        # print(i_n)\n",
    "        kp_neighbours=[]\n",
    "        desc_neighbours=[]\n",
    "        for neigh in i_n: # Iterates over the indices of the k nearest neighbours of the instance being predicted\n",
    "            img=data[neigh]\n",
    "            gray_neighbour= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)# A neighbour of the instances being predicted\n",
    "            kp, des = sift.detectAndCompute(gray_neighbour,None) # key points and descriptors of the neighbour of instance being predicted\n",
    "            kp_neighbours.append(kp)\n",
    "            desc_neighbours.append(des)\n",
    "\n",
    "        key_points.append(kp_neighbours)\n",
    "        descriptors.append(desc_neighbours)\n",
    "    \n",
    "    return key_points, descriptors\n",
    "\n",
    "kpts,descriptors2=generate_descriptors_neighbours(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a114d2e6-fa10-47ce-80a4-0f3facd2c94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors2[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3d843052-abf1-45ca-b9f2-985d79eaf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generates de key points and descriptors of the images to be predicted\n",
    "validation_img=data[7000:]\n",
    "\n",
    "def generate_descriptors(data_img):\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    key_points=[]\n",
    "    descript=[]\n",
    "\n",
    "    for  img in data_img: #Iterate over indices of predictions\n",
    "        # print(i_n)\n",
    "        gray= cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        kp, des = sift.detectAndCompute(gray,None) # key points and descriptors of the instance being predicted\n",
    "        key_points.append(kp)\n",
    "        descript.append(des)\n",
    "    \n",
    "    return key_points, descript\n",
    "\n",
    "kp, descriptors1 = generate_descriptors(validation_img)\n",
    "#descript_dev=np.array(descript_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4f87955e-b62c-4252-914f-8b9831fa6fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(descriptors1[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "14a77884-50af-4dd6-9a62-3f64b69b3df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matches(matcher,des1, des2):\n",
    "    # Matching descriptor using KNN algorithm\n",
    "    try:\n",
    "        matches = matcher.knnMatch(des1,des2,k=2)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Store all good matches as per Lowe's Ratio test.\n",
    "    ratio = 0.6\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < ratio*n.distance:\n",
    "            good.append(m)\n",
    "    return len(good)\n",
    "\n",
    "def match(desc_list1, desc_list2, predictions):\n",
    "    \n",
    "    # FLANN parameters and initialize\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    best_neighbours_matched=[]\n",
    "    for i, desc1 in enumerate(desc_list1):\n",
    "        # print('\\n\\n')\n",
    "        # print('image {}'.format(i))\n",
    "        matches_list=[]\n",
    "        ind_neighbour=[]\n",
    "        for j, desc2 in enumerate(desc_list2[i]):\n",
    "            #print(j)\n",
    "            if desc2 is not None:\n",
    "                #print('neighb {}'.format(j))\n",
    "                n_matches = find_matches(flann, desc1, desc2)\n",
    "                if n_matches is not None:\n",
    "                    ind_neighbour.append(predictions[1][i][j]) #Appends index in the data of the neighbour from the image being predicted\n",
    "                    matches_list.append(n_matches) #Appends matches between the current neighbour and the instance being predicted\n",
    "                else:\n",
    "                    continue\n",
    "        \n",
    "        #print('len ind neigh',ind_neighbour)\n",
    "        #print('len matches list',matches_list)\n",
    "        neighb_matches=np.stack([ind_neighbour,matches_list],axis=1) #Creates numpy array. Rows are descriptors of different neighbours. \n",
    "                                                                     # First column is index in the data, Second column is how many matches that neighbour has with the current instance\n",
    "        neighb_matches=neighb_matches[neighb_matches[:, 1].argsort()[::-1][:len(matches_list)]]  #Sorts array in descending order, more matches on top and less matches at the bottom :5 is the number of neighbours\n",
    "        #print(neighb_matches)\n",
    "        best_neighbours_matched.append(neighb_matches)\n",
    "    \n",
    "    return best_neighbours_matched\n",
    "                                 \n",
    "k_best_matches=match(descriptors1,descriptors2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4098d012-9532-482a-9f4a-1cd95601f2b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 2), dtype=float64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_best_matches[]\n",
    "#len(k_best_matches)\n",
    "#for k in range(len(k_best_matches)):\n",
    "#    print(k)\n",
    "#    k_best_matches[k][0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced1e945-4b43-4de2-b58d-9bae48f4266d",
   "metadata": {},
   "source": [
    "## TEST predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a475d1f4-f410-44b5-a289-88f3d83447e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root= './test'\n",
    "names_test, test_img = load_data(root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "62492e99-38a2-4c5f-a104-b71e0ca1fb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_feat=generate_features(test_img,base_model, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b5a03ca6-4dd2-4791-bbce-f54f71f53224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 98304)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "206a54b1-c125-426f-acc5-0c77a56a4e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_neigh = get_nearest_neighbours(feat, test_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7d80997f-2708-4f76-93c8-2f57d0b19449",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps, descript_neigh = generate_descriptors_neighbours(predicted_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5e8eda8b-8e03-4999-9ed4-ef44def0f062",
   "metadata": {},
   "outputs": [],
   "source": [
    "kps2, descript_test=generate_descriptors(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6f725788-d7d8-4b48-9bcb-89107036342d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_best_matches_test=match(descript_test, descript_neigh,predicted_neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b987af95-f547-4aba-8322-bed243796dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def give_preds(k_best_matches_test,predicted_neigh, df_coordinates,names_test):\n",
    "    \"\"\"Peforms the prediction for the test_set using the k best matches or the best neighbours in case there are no matches produced by SIFT\n",
    "\n",
    "    Keyword arguments:\n",
    "    k_best_matches_test -- k best matches list generated by feature matching using SIFT\n",
    "    predicted_neigh -- predicted k nearest neighbours by the pre-trained model\n",
    "    df_coordinates -- dataframe where the coordinates of the training points are\n",
    "    names_test =\n",
    "    \"\"\"\n",
    "    pred_coordinates=[]\n",
    "    record_no_matches=[]\n",
    "    for i, best in enumerate(k_best_matches_test):\n",
    "        if best.size != 0:\n",
    "            index_best=best[0][0] # This is the index of the neighbour with more matches\n",
    "            pred_coordinates.append([names_test[i],df_coordinates.loc[index_best,'x'],df_coordinates.loc[index_best,'y']])\n",
    "        else:\n",
    "            # if there were no matches, use the average of the locations of the neighbours found by the pre-trained model\n",
    "            x_coord=np.array([df_coordinates.loc[j,'x'] for j in predicted_neigh[1][i]]).mean()\n",
    "            y_coord=np.array([df_coordinates.loc[j,'y'] for j in predicted_neigh[1][i]]).mean()\n",
    "            pred_coordinates.append([names_test[i], x_coord, y_coord])\n",
    "    \n",
    "    array_preds=np.stack(pred_coordinates, axis=0)\n",
    "   \n",
    "    df_predictions=pd.DataFrame(array_preds, columns=['id','x','y'])\n",
    "    return df_predictions\n",
    "\n",
    "#Load the coordinates data set\n",
    "coordinates = pd.read_csv('train.csv')\n",
    "            \n",
    "df_preds = give_preds(k_best_matches_test, predicted_neigh, coordinates,names_test)\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6934096a-cf47-4925-ae85-a4906740a02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preds.to_csv('resnet_knn_sift.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fb24e09c-cc3d-4e89-8620-5d5c38e767a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "14\n",
      "17\n",
      "30\n",
      "34\n",
      "46\n",
      "57\n",
      "81\n",
      "86\n",
      "99\n",
      "100\n",
      "102\n",
      "131\n",
      "160\n",
      "168\n",
      "177\n",
      "188\n",
      "209\n",
      "216\n",
      "223\n",
      "228\n",
      "286\n",
      "300\n",
      "313\n",
      "331\n",
      "341\n",
      "343\n",
      "353\n",
      "360\n",
      "370\n",
      "375\n",
      "377\n",
      "385\n",
      "399\n",
      "404\n",
      "411\n",
      "412\n",
      "417\n",
      "426\n",
      "430\n",
      "450\n",
      "463\n",
      "525\n",
      "548\n",
      "557\n",
      "586\n",
      "587\n",
      "594\n",
      "605\n",
      "613\n",
      "625\n",
      "647\n",
      "657\n",
      "663\n",
      "670\n",
      "707\n",
      "737\n",
      "755\n",
      "773\n",
      "791\n",
      "793\n",
      "795\n",
      "816\n",
      "826\n",
      "828\n",
      "874\n",
      "877\n",
      "888\n",
      "889\n",
      "901\n",
      "924\n",
      "929\n",
      "958\n",
      "965\n",
      "976\n",
      "977\n",
      "981\n",
      "983\n",
      "991\n",
      "996\n",
      "1001\n",
      "1020\n",
      "1021\n",
      "1023\n",
      "1024\n",
      "1040\n",
      "1044\n",
      "1057\n",
      "1061\n",
      "1069\n",
      "1072\n",
      "1079\n",
      "1086\n",
      "1093\n",
      "1128\n",
      "1130\n",
      "1131\n",
      "1145\n",
      "1147\n",
      "1152\n",
      "1161\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "104\n"
     ]
    }
   ],
   "source": [
    "coubnnt=0\n",
    "for k in range(len(k_best_matches_test)):\n",
    "    if k_best_matches_test[k].size ==0:\n",
    "        print(k)\n",
    "        coubnnt+=1\n",
    "    else:\n",
    "        continue\n",
    "        #print(k_best_matches_test[k][0][1])\n",
    "print(coubnnt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
