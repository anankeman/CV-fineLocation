{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2  \n",
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in images from a filepath as graycsale.\n",
    "rootpath='./'\n",
    "\n",
    "\n",
    "# Reads the images in the training set\n",
    "df_img=pd.read_csv('train.csv')\n",
    "df_img['img']=[None]*len(df_img['id'])\n",
    "df_img.set_index('id',inplace=True)\n",
    "\n",
    "\n",
    "#Creates dict with key = id, and a list with positions 0: x coordinate, 1: y coordinate, 2: array representing img\n",
    "#dict_img=defaultdict(list)\n",
    "\n",
    "\n",
    "'''\n",
    "for i in range(len(df_coord['id'])):\n",
    "    id_img=df_coord.loc[i,'id']\n",
    "    x_coord=df_coord.loc[i,'x']\n",
    "    y_coord=df_coord.loc[i,'y']\n",
    "    dict_img[id_img].append(x_coord)\n",
    "    dict_img[id_img].append(y_coord)\n",
    "'''\n",
    "    \n",
    "img_name_list=[]\n",
    "edge_img_list=\n",
    "for i, filename in enumerate(os.listdir(os.path.join(rootpath, 'train/'))):\n",
    "    #if i>1:\n",
    "    #    break\n",
    "    img = cv2.imread(os.path.join(rootpath, f'train/{filename}'),cv2.IMREAD_GRAYSCALE)\n",
    "    #print(img)\n",
    "    file_name_no_ext=filename.replace('.jpg','')\n",
    "    img_name_list.append(file_name_no_ext)\n",
    "    \n",
    "    #dict_img[file_name_no_ext].append(img)\n",
    "    df_img.loc[file_name_no_ext,'img']=[img]\n",
    "    \n",
    "    #lt.imshow(img_gray, cmap='gray')\n",
    "    #lt.show()\n",
    "\n",
    "\n",
    "print(df_img)\n",
    "\n",
    "'''\n",
    "# Display original image and scene image\n",
    "plt.subplots(figsize=(15, 15)) \n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(gray, cmap='gray')  \n",
    "plt.title('Original Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(scene_gray, cmap='gray')  \n",
    "plt.title('Scene Image')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.show() \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sift = cv2.SIFT_create()\n",
    "\n",
    "kp_list=[]\n",
    "desc_list=[]\n",
    "for m, i in enumerate(df_img.index):\n",
    "    #if  m>1:\n",
    "    #    break\n",
    "    image=df_img.loc[i,'img']\n",
    "    kp, des = sift.detectAndCompute(image,None) \n",
    "    #rint(kp)\n",
    "    kp_list.append(kp)\n",
    "    desc_list.append(des)\n",
    "\n",
    "df_img['kps']=kp_list\n",
    "df_img['desc']=desc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_img_test=pd.read_csv('imagenames.csv')\n",
    "df_img_test['img']=[None]*len(df_img_test['id'])\n",
    "df_img_test.set_index('id',inplace=True)\n",
    "\n",
    "test_img_name_list=[]\n",
    "for i, filename in enumerate(os.listdir(os.path.join(rootpath, 'test/'))):\n",
    "    #if i>1:\n",
    "    #    break\n",
    "    img = cv2.imread(os.path.join(rootpath, f'test/{filename}'),cv2.IMREAD_GRAYSCALE)\n",
    "    #print(img)\n",
    "    test_file_name_no_ext=filename.replace('.jpg','')\n",
    "    test_img_name_list.append(test_file_name_no_ext)\n",
    "    \n",
    "    #dict_img[file_name_no_ext].append(img)\n",
    "    df_img_test.loc[test_file_name_no_ext,'img']=img\n",
    "    \n",
    "#GENERATE KEYPOINTS AND DESCRIPTORS\n",
    "    \n",
    "kp_test_list=[]\n",
    "desc_test_list=[]\n",
    "for m, i in enumerate(df_img_test.index):\n",
    "    #if  m>1:\n",
    "    #    break\n",
    "    image=df_img_test.loc[i,'img']\n",
    "    kp, des = sift.detectAndCompute(image,None) \n",
    "    #rint(kp)\n",
    "    kp_test_list.append(kp)\n",
    "    desc_test_list.append(des)\n",
    "\n",
    "df_img_test['kps']=kp_test_list\n",
    "df_img_test['desc']=desc_test_list\n",
    "\n",
    "df_img_test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "indices=df_img.index.to_list()\n",
    "\n",
    "indices\n",
    "X_train, X_dev, _, _=train_test_split(indices, indices, test_size= 0.01, random_state=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_matches(matcher,des1, des2):\n",
    "    # Matching descriptor using KNN algorithm\n",
    "    matches = matcher.knnMatch(des1,des2,k=2)\n",
    "\n",
    "    # Store all good matches as per Lowe's Ratio test.\n",
    "    ratio = 0.6\n",
    "    good = []\n",
    "    for m,n in matches:\n",
    "        if m.distance < ratio*n.distance:\n",
    "            good.append(m)\n",
    "    return len(good)\n",
    "\n",
    "def match(df, known, unknown):\n",
    "    \n",
    "    # FLANN parameters and initialize\n",
    "    FLANN_INDEX_KDTREE = 1\n",
    "    index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "    search_params = dict(checks=50)   # or pass empty dictionary\n",
    "    flann = cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "    \n",
    "    df_img1=df.copy() #Copies original df\n",
    "    \n",
    "    array=np.full((len(X_train),len(X_dev)),np.nan)    \n",
    "    df_matches=pd.DataFrame(array,columns=unknown)\n",
    "    df_matches['ind']=known\n",
    "    df_matches.set_index('ind', inplace=True)\n",
    "    \n",
    "    for u in unknown:\n",
    "        desc2=df_img1.loc[u,'desc']\n",
    "        \n",
    "        for k in known:\n",
    "            print(k)\n",
    "            desc1=df_img1.loc[k,'desc']\n",
    "            \n",
    "            #print(desc1)\n",
    "            print(desc2)\n",
    "            df_matches.loc[k,u]= find_matches(flann, desc1, desc2)\n",
    "    \n",
    "    return df_matches\n",
    "\n",
    "good=match(df_img, X_train, X_dev)\n",
    "            \n",
    "\n",
    "\n",
    "good      \n",
    "            \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "#df_img1['matches']=df_img1['matches'].map(lambda x: match(x))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "lista=[]\n",
    "lista.append([X_train])\n",
    "\n",
    "train_descriptors=[]\n",
    "y1_train=[]\n",
    "y2_train=[]\n",
    "for k in X_train:\n",
    "    train_descriptors.append(df_img.loc[k,'desc'])    \n",
    "    y1_train.append(df_img.loc[k,'x'])\n",
    "    y2_train.append(df_img.loc[k,'y'])\n",
    "    \n",
    "\n",
    "index_none=[]\n",
    "even_descr=[]\n",
    "for i, t in enumerate(train_descriptors):\n",
    "    if t is not None:\n",
    "        even_descr.append(np.mean(t,axis=0))\n",
    "    else:\n",
    "        index_none.append(i)\n",
    "\n",
    "#print(even_descr)\n",
    "y1_t=[]\n",
    "y2_t=[]\n",
    "for i,k in enumerate(y1_train):\n",
    "    if i not in index_none:\n",
    "        y1_t.append(y1_train[i])\n",
    "        y2_t.append(y2_train[i])\n",
    "        \n",
    "\n",
    "dev_descriptors=[]\n",
    "y1_dev=[]\n",
    "y2_dev=[]\n",
    "index_none_dev=[]\n",
    "for i, d in enumerate(X_dev):\n",
    "    if d is not None:\n",
    "        desc= df_img.loc[d,'desc']\n",
    "        dev_descriptors.append(np.mean(desc,axis=0))\n",
    "        y1_dev.append(df_img.loc[d,'x'])\n",
    "        y2_dev.append(df_img.loc[d,'y'])\n",
    "    else:\n",
    "        index_none_dev.append(i)\n",
    "    \n",
    "dev_coord=np.column_stack((y1_dev,y2_dev))\n",
    "    \n",
    "train_coord=np.column_stack((y1_t,y2_t))\n",
    "\n",
    "print('original lenght descr:',len(train_descriptors))\n",
    "print('even lenght descr:',len(even_descr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "regressor=MultiOutputRegressor(GradientBoostingRegressor(random_state=0, criterion='mae',n_estimators=500)).fit(even_descr,train_coord)\n",
    "\n",
    "result= regressor.predict(test_descriptors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def mean_abs_err(truth, preds):\n",
    "    \n",
    "    error=0\n",
    "    for i, pred in enumerate(preds):\n",
    "        error+= abs(truth[i][0]-preds[i][0])+abs(truth[i][1]-preds[i][1])\n",
    "        \n",
    "    return error/len(preds)\n",
    "\n",
    "mae=mean_abs_err(dev_coord,result )\n",
    "mae\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "X, y = make_regression(n_samples=10, n_targets=3, random_state=1)\n",
    "#MultiOutputRegressor(GradientBoostingRegressor(random_state=0)).fit(X, y).predict(X)\n",
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
